{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NCDPI 2018-2019 Raw Datasets\n",
    "### This program downloads all original datasets from www.ncpublicschools.org and saves them as .csv files. These data files are used to create all the flattened and machine learning datasets within the NCEA repository.\n",
    "\n",
    "1. This notebook downloads raw datasets directly from NCDPI specific URLs.\n",
    "2. Each raw dataset is filtered by school year and saved in the original layout as a .csv file.\n",
    "3. For consistency, both the Year and School code fields are renamed to \"year\" and \"agency_code\" in all files.\n",
    "4. All masking is removed from raw data fields using the following code: replace({\"*\":0, \">95\":100, \"<5\":0, \"<10\":5 })\n",
    "5. All * or carriage returns are removed from column names.\n",
    "6. All raw datasets created by this program are used to create the \"flattened\" and \"machine learning\" Public School datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#**********************************************************************************\n",
    "# Set the following variables before running this code!!!\n",
    "#**********************************************************************************\n",
    "\n",
    "#Location where copies of the raw data files will be downloaded and saved as csv files.\n",
    "#'C:/Users/Jake/Documents/GitHub/EducationDataNC/2018/Raw Datasets/'\n",
    "dataDir = 'D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/'\n",
    "\n",
    "#All raw data files are filtered for the year below\n",
    "schoolYear = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save Copy of the Original SRC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os \n",
    "\n",
    "#Download and save an original copy of the raw SRC data \n",
    "url=\"https://files.nc.gov/dpi/src_datasets.zip\"\n",
    "zipFilePath = dataDir + 'src_datasets-2020-06.zip'\n",
    "\n",
    "#Comment out the next line after downloading the original data one time! \n",
    "#urllib.request.urlretrieve(url, zipFilePath)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "#Extract the zip file and all school datasets to the //Raw Datasets/ folder\n",
    "zip_ref = zipfile.ZipFile(zipFilePath, 'r')\n",
    "zip_ref.extractall(dataDir + 'SRC_Datasets/')\n",
    "zip_ref.close()\n",
    "\n",
    "#Remove any corrupt files\n",
    "\n",
    "#Remove Lookup Tables\n",
    "os.remove(dataDir + 'SRC_Datasets/' + \"rcd_code_desc.xlsx\")\n",
    "os.remove(dataDir + 'SRC_Datasets/' + \"rcd_ap_crs_list.xlsx\")\n",
    "os.remove(dataDir + 'SRC_Datasets/' + \"rcd_cte_enrollment_cluster.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Delete corrupt record from rcd_sat.xlsx\n",
    "filePath = dataDir + 'SRC_Datasets/' + 'rcd_sat.xlsx'\n",
    "rcdSat = pd.read_excel(filePath, dtype={'agency_code': object})\n",
    "rcdSat = rcdSat[rcdSat.year != '/*20']\n",
    "\n",
    "#Save file without the bold column headings\n",
    "import pandas.io.formats.excel\n",
    "pandas.io.formats.excel.header_style = None\n",
    "rcdSat.to_excel(filePath,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rcd_acc_pc file from tab into csv format.\n",
    "file_pth = dataDir + 'SRC_Datasets/rcd_acc_pc' \n",
    "df = pd.read_csv(file_pth + '.txt', sep='\\t', dtype={'year':int}, low_memory=False)\n",
    "# Get the most recent year, since the file is VERY large\n",
    "df = df[df.year == 2019]\n",
    "# Save the file in .csv format\n",
    "df.to_csv(file_pth + '.csv' , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct column heading in rcd_improvement2.csv\n",
    "# agengy_code ---> agency_code\n",
    "filePath = dataDir + 'SRC_Datasets/' + 'rcd_improvement2.xlsx'\n",
    "df = pd.read_excel(filePath, dtype={'agency_code': object})\n",
    "df.rename(columns={'agengy_code': 'agency_code'}, inplace=True)\n",
    "df.to_excel(filePath,index=False)\n",
    "\n",
    "# Correct column heading in rcd_funds2.csv\n",
    "# expenditure_categoy ---> expenditure_category\n",
    "filePath = dataDir + 'SRC_Datasets/' + 'rcd_funds2.xlsx'\n",
    "df = pd.read_excel(filePath, dtype={'agency_code': object})\n",
    "df.rename(columns={'expenditure_categoy': 'expenditure_category'}, inplace=True)\n",
    "df.to_excel(filePath,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Files\n",
      "------------------------------------\n",
      "rcd_161\n",
      "rcd_acc_aapart\n",
      "rcd_acc_act\n",
      "rcd_acc_awa\n",
      "rcd_acc_cgr\n",
      "rcd_acc_eds\n",
      "rcd_acc_eg\n",
      "rcd_acc_elp\n",
      "rcd_acc_essa_desig\n",
      "rcd_acc_gp\n",
      "rcd_acc_irm\n",
      "rcd_acc_lowperf\n",
      "rcd_acc_ltg\n",
      "rcd_acc_ltg_detail\n",
      "rcd_acc_mcr\n",
      "rcd_acc_part\n",
      "rcd_acc_part_detail\n",
      "rcd_acc_rta\n",
      "rcd_acc_spg1\n",
      "rcd_acc_spg2\n",
      "rcd_acc_wk\n",
      "rcd_adm\n",
      "rcd_ap\n",
      "rcd_arts\n",
      "rcd_att\n",
      "rcd_charter\n",
      "rcd_chronic_absent\n",
      "rcd_college\n",
      "rcd_courses1\n",
      "rcd_courses2\n",
      "rcd_cte_concentrators\n",
      "rcd_cte_credentials\n",
      "rcd_cte_endorsement\n",
      "rcd_cte_enrollment\n",
      "rcd_dlmi\n",
      "rcd_effectiveness\n",
      "rcd_effectiveness3\n",
      "rcd_eq\n",
      "rcd_esea_att\n",
      "rcd_experience\n",
      "rcd_funds\n",
      "rcd_funds2\n",
      "rcd_hqt\n",
      "rcd_ib\n",
      "rcd_improvement\n",
      "rcd_improvement2\n",
      "rcd_inc1\n",
      "rcd_inc2\n",
      "rcd_licenses\n",
      "rcd_location\n",
      "rcd_naep\n",
      "rcd_nbpts\n",
      "rcd_pk_enroll\n",
      "rcd_prin_demo\n",
      "rcd_readiness\n",
      "rcd_sar\n",
      "rcd_sat\n",
      "rcd_welcome\n"
     ]
    }
   ],
   "source": [
    "#Use wildcards to find files in a directory\n",
    "import glob\n",
    "import ntpath \n",
    "\n",
    "#Get all .xlsx files \n",
    "xlsFiles = glob.glob(dataDir + 'SRC_Datasets/' + '*.xlsx')\n",
    "txtFiles = glob.glob(dataDir + 'SRC_Datasets/' + '*.txt')\n",
    "csvFiles = glob.glob(dataDir + 'SRC_Datasets/' + '*.csv')\n",
    "csvNames = [ os.path.splitext(ntpath.basename(i))[0] for i in csvFiles]\n",
    "\n",
    "print('Converted Files')\n",
    "print('------------------------------------')\n",
    "\n",
    "# Convert any missing .xlsx files to csv \n",
    "for xlsPath in xlsFiles:\n",
    "    # Get file name with no extension\n",
    "    xlsName = os.path.splitext(ntpath.basename(xlsPath))[0]\n",
    "    # if we DO NOT have this xls file in csv format\n",
    "    if xlsName not in csvNames: \n",
    "        # Convert the xls file to csv\n",
    "        df = pd.read_excel(xlsPath, dtype={'agency_code': object, 'year':int})\n",
    "        df.to_csv(dataDir + 'SRC_Datasets/' + xlsName + '.csv' , index=False)\n",
    "        print(xlsName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Duplicate xls and txt Files\n",
      "------------------------------------\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_161.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_aapart.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_act.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_awa.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_cgr.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_eds.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_eg.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_elp.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_essa_desig.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_gp.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_irm.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_lowperf.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_ltg.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_ltg_detail.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_mcr.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_part.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_part_detail.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_rta.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_spg1.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_spg2.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_wk.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_adm.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_ap.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_arts.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_att.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_charter.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_chronic_absent.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_college.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_courses1.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_courses2.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_cte_concentrators.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_cte_credentials.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_cte_endorsement.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_cte_enrollment.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_dlmi.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_effectiveness.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_effectiveness3.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_eq.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_esea_att.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_experience.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_funds.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_funds2.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_hqt.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_ib.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_improvement.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_improvement2.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_inc1.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_inc2.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_licenses.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_location.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_naep.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_nbpts.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_pk_enroll.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_prin_demo.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_readiness.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_sar.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_sat.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_welcome.xlsx\n",
      "D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/SRC_Datasets\\rcd_acc_pc.txt\n"
     ]
    }
   ],
   "source": [
    "# Delete all the xls and text files\n",
    "print('Deleted Duplicate xls and txt Files')\n",
    "print('------------------------------------')\n",
    "for fp in xlsFiles + txtFiles: \n",
    "    os.remove(fp)\n",
    "    print(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Most Recent Year of Data from Each File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use ntpath.basename to get a filename from a filepath\n",
    "import ntpath\n",
    "\n",
    "def CleanUpRcdFiles(filePath):\n",
    "    fileName = ntpath.basename(filePath)\n",
    "    schFile = pd.read_csv(filePath, dtype={'agency_code': object, 'year':int}, low_memory=False)\n",
    "    maxYear = schFile['year'].max()\n",
    "    \n",
    "    #Filter records for the most recent year\n",
    "    schFile = schFile[schFile['year'] == maxYear]\n",
    "    \n",
    "    #Remove state and district level summary records \n",
    "    schFile = schFile[(schFile['agency_code'] != 'NC-SEA') & (schFile['agency_code'].str.contains(\"LEA\") == False)]\n",
    "        \n",
    "    #Remove * character from any fields. \n",
    "    schFile = schFile.replace({'*':''})\n",
    "    schFile.to_csv(dataDir + 'SRC_Datasets/' + fileName, sep=',', index=False)\n",
    "    \n",
    "    print(fileName + ', Max Year: ' + str(maxYear))\n",
    "    return (fileName, maxYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Files to: D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/May 2020/2019/Raw Datasets/\n",
      "\n",
      "rcd_161.csv, Max Year: 2012\n",
      "rcd_acc_aapart.csv, Max Year: 2019\n",
      "rcd_acc_act.csv, Max Year: 2019\n",
      "rcd_acc_awa.csv, Max Year: 2019\n",
      "rcd_acc_cgr.csv, Max Year: 2019\n",
      "rcd_acc_eds.csv, Max Year: 2019\n",
      "rcd_acc_eg.csv, Max Year: 2019\n",
      "rcd_acc_elp.csv, Max Year: 2019\n",
      "rcd_acc_essa_desig.csv, Max Year: 2019\n",
      "rcd_acc_gp.csv, Max Year: 2019\n",
      "rcd_acc_irm.csv, Max Year: 2019\n",
      "rcd_acc_lowperf.csv, Max Year: 2019\n",
      "rcd_acc_ltg.csv, Max Year: 2019\n",
      "rcd_acc_ltg_detail.csv, Max Year: 2019\n",
      "rcd_acc_mcr.csv, Max Year: 2019\n",
      "rcd_acc_part.csv, Max Year: 2019\n",
      "rcd_acc_part_detail.csv, Max Year: 2019\n",
      "rcd_acc_pc.csv, Max Year: 2019\n",
      "rcd_acc_rta.csv, Max Year: 2019\n",
      "rcd_acc_spg1.csv, Max Year: 2017\n",
      "rcd_acc_spg2.csv, Max Year: 2019\n",
      "rcd_acc_wk.csv, Max Year: 2019\n",
      "rcd_adm.csv, Max Year: 2019\n",
      "rcd_ap.csv, Max Year: 2019\n",
      "rcd_arts.csv, Max Year: 2019\n",
      "rcd_att.csv, Max Year: 2018\n",
      "rcd_charter.csv, Max Year: 2019\n",
      "rcd_chronic_absent.csv, Max Year: 2019\n",
      "rcd_college.csv, Max Year: 2019\n",
      "rcd_courses1.csv, Max Year: 2017\n",
      "rcd_courses2.csv, Max Year: 2019\n",
      "rcd_cte_concentrators.csv, Max Year: 2019\n",
      "rcd_cte_credentials.csv, Max Year: 2019\n",
      "rcd_cte_endorsement.csv, Max Year: 2019\n",
      "rcd_cte_enrollment.csv, Max Year: 2019\n",
      "rcd_dlmi.csv, Max Year: 2019\n",
      "rcd_effectiveness.csv, Max Year: 2018\n",
      "rcd_effectiveness3.csv, Max Year: 2019\n",
      "rcd_eq.csv, Max Year: 2019\n",
      "rcd_esea_att.csv, Max Year: 2015\n",
      "rcd_experience.csv, Max Year: 2018\n",
      "rcd_funds.csv, Max Year: 2018\n",
      "rcd_funds2.csv, Max Year: 2019\n",
      "rcd_hqt.csv, Max Year: 2016\n",
      "rcd_ib.csv, Max Year: 2019\n",
      "rcd_improvement.csv, Max Year: 2018\n",
      "rcd_improvement2.csv, Max Year: 2019\n",
      "rcd_inc1.csv, Max Year: 2017\n",
      "rcd_inc2.csv, Max Year: 2019\n",
      "rcd_licenses.csv, Max Year: 2018\n",
      "rcd_location.csv, Max Year: 2019\n",
      "rcd_naep.csv, Max Year: 2019\n",
      "rcd_nbpts.csv, Max Year: 2018\n",
      "rcd_pk_enroll.csv, Max Year: 2019\n",
      "rcd_prin_demo.csv, Max Year: 2019\n",
      "rcd_readiness.csv, Max Year: 2019\n",
      "rcd_sar.csv, Max Year: 2019\n",
      "rcd_sat.csv, Max Year: 2019\n",
      "rcd_welcome.csv, Max Year: 2019\n"
     ]
    }
   ],
   "source": [
    "#Use wildcards to find files in a directory\n",
    "import glob\n",
    "import os\n",
    "#Get and display a list of all .csv file names for 2019 download\n",
    "rcdFiles = glob.glob(dataDir + 'SRC_Datasets/' + 'rcd*.csv')\n",
    "\n",
    "print('Saving Files to: ' + dataDir + '\\n')\n",
    "\n",
    "file_data_years = []\n",
    "for filePth in rcdFiles:\n",
    "    fileName = ntpath.basename(filePth)\n",
    "    file_data_years.append(CleanUpRcdFiles(filePth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually remove what appear to be retired data files\n",
    "\n",
    "# rcd_161.csv, Max Year: 2012, appears retired\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_161.csv')\n",
    "# rcd_esea_att.csv, Max Year: 2015, appears retired\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_esea_att.csv')\n",
    "# rcd_hqt.csv, Max Year: 2016, appears retired\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_hqt.csv')\n",
    "# rcd_att.csv, Max Year: 2018, retired\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_att.csv')\n",
    "# rcd_licenses, Max Year: 2018, retired \n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_licenses.csv')\n",
    "# rcd_nbpts, Max Year: 2018, retired \n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_nbpts.csv')\n",
    "# rcd_experience, Max Year: 2018, retired \n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_experience.csv')\n",
    "\n",
    "# Manually remove any split data files that do not have data for the current year. \n",
    "\n",
    "# rcd_acc_spg1.csv, Max Year: 2017, rcd_acc_spg2 has 2019\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_acc_spg1.csv')\n",
    "# rcd_courses1.csv, Max Year: 2017, rcd_courses2 has 2019 \n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_courses1.csv')\n",
    "# rcd_effectiveness.csv, Max Year: 2018, rcd_effectiveness3 has 2019\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_effectiveness.csv')\n",
    "# rcd_improvement.csv, Max Year: 2018, rcd_improvement2 has 2019\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_improvement.csv')\n",
    "# rcd_inc1.csv, Max Year: 2017, rcd_inc2 has 2019\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_inc1.csv')\n",
    "# rcd_funds.csv, Max Year: 2018, rcd_funds2 has 2019\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_funds.csv')\n",
    "\n",
    "# Manually remove files that do not have campus level data\n",
    "# rcd_neap.csv, National Data Only\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_naep.csv')\n",
    "# rcd_prin_demo.csv, 1 column of District Level Data Only\n",
    "os.remove(dataDir + 'SRC_Datasets/' + 'rcd_prin_demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Files\n",
      "----------------------------------\n",
      "('rcd_acc_aapart.csv', 2019)\n",
      "('rcd_acc_act.csv', 2019)\n",
      "('rcd_acc_awa.csv', 2019)\n",
      "('rcd_acc_cgr.csv', 2019)\n",
      "('rcd_acc_eds.csv', 2019)\n",
      "('rcd_acc_eg.csv', 2019)\n",
      "('rcd_acc_elp.csv', 2019)\n",
      "('rcd_acc_essa_desig.csv', 2019)\n",
      "('rcd_acc_gp.csv', 2019)\n",
      "('rcd_acc_irm.csv', 2019)\n",
      "('rcd_acc_lowperf.csv', 2019)\n",
      "('rcd_acc_ltg.csv', 2019)\n",
      "('rcd_acc_ltg_detail.csv', 2019)\n",
      "('rcd_acc_mcr.csv', 2019)\n",
      "('rcd_acc_part.csv', 2019)\n",
      "('rcd_acc_part_detail.csv', 2019)\n",
      "('rcd_acc_pc.csv', 2019)\n",
      "('rcd_acc_rta.csv', 2019)\n",
      "('rcd_acc_spg2.csv', 2019)\n",
      "('rcd_acc_wk.csv', 2019)\n",
      "('rcd_adm.csv', 2019)\n",
      "('rcd_ap.csv', 2019)\n",
      "('rcd_arts.csv', 2019)\n",
      "('rcd_charter.csv', 2019)\n",
      "('rcd_chronic_absent.csv', 2019)\n",
      "('rcd_college.csv', 2019)\n",
      "('rcd_courses2.csv', 2019)\n",
      "('rcd_cte_concentrators.csv', 2019)\n",
      "('rcd_cte_credentials.csv', 2019)\n",
      "('rcd_cte_endorsement.csv', 2019)\n",
      "('rcd_cte_enrollment.csv', 2019)\n",
      "('rcd_dlmi.csv', 2019)\n",
      "('rcd_effectiveness3.csv', 2019)\n",
      "('rcd_eq.csv', 2019)\n",
      "('rcd_funds2.csv', 2019)\n",
      "('rcd_ib.csv', 2019)\n",
      "('rcd_improvement2.csv', 2019)\n",
      "('rcd_inc2.csv', 2019)\n",
      "('rcd_location.csv', 2019)\n",
      "('rcd_naep.csv', 2019)\n",
      "('rcd_pk_enroll.csv', 2019)\n",
      "('rcd_readiness.csv', 2019)\n",
      "('rcd_sar.csv', 2019)\n",
      "('rcd_sat.csv', 2019)\n",
      "('rcd_welcome.csv', 2019)\n"
     ]
    }
   ],
   "source": [
    "# Update our file lists\n",
    "file_data_years = [i for i in file_data_years if i[0] not in \n",
    "                   ['rcd_161.csv','rcd_esea_att.csv','rcd_hqt.csv','rcd_acc_spg1.csv','rcd_courses1.csv',\n",
    "                    'rcd_effectiveness.csv', 'rcd_improvement.csv', 'rcd_inc1.csv', 'rcd_licenses.csv',\n",
    "                    'rcd_att.csv','rcd_experience.csv', 'rcd_funds.csv','rcd_nbpts.csv','rcd_prin_demo.csv']]\n",
    "\n",
    "rcdFiles = glob.glob(dataDir + 'SRC_Datasets/' + 'rcd*.csv') \n",
    "\n",
    "print('Remaining Files')\n",
    "print('----------------------------------')\n",
    "\n",
    "for f in file_data_years:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten the Raw Data Files\n",
    "### This section reads raw data files directly from the \\\\Raw Datasets folder and flattens each file.\n",
    "1. Each agency_code could represent National, State, District, Or School Campus level data.\n",
    "2. This code creates new data columns using pivots until there is only one record per agency_code.\n",
    "3. Percentage fields are typically used for pivot values in cases where count, denominators, or percentages are available.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PivotCsv(dataDir, fileName, pivValues, pivIndex, pivColumns, colSuffix):\n",
    "    pivFile = pd.read_csv(dataDir + fileName, low_memory=False, dtype={pivIndex: object})\n",
    "    \n",
    "    pivFile = pd.pivot_table(pivFile, values=pivValues,index=pivIndex,columns=pivColumns)\n",
    "    \n",
    "    #concatenate multiindex column names using a list comprehension.\n",
    "    pivFile.columns = [ '_'.join(str(i) for i in col) + colSuffix for col in pivFile.columns]\n",
    "\n",
    "    #Make our index a column for merges later\n",
    "    pivFile.reset_index(level=0, inplace=True)\n",
    "    return pivFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use table pivots to flatten each dataset\n",
    "* Each dataset is converted to one record per agency code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcDir = dataDir + 'SRC_Datasets/'\n",
    "\n",
    "# Pivot File - rcd_161 - Appears retired 2012\n",
    "# rcd_161 = PivotCsv(srcDir, 'rcd_161.csv',['ccc_pct'],'agency_code', ['status','subgroup'],'_161')\n",
    "\n",
    "# Pivot File - rcd_acc_aapart \n",
    "rcd_acc_aapart = PivotCsv(srcDir, 'rcd_acc_aapart.csv',['pct'],'agency_code', ['subject','grade'],'_AAPART')\n",
    "rcd_acc_aapart.columns = [i.lower() for i in rcd_acc_aapart.columns]\n",
    "\n",
    "# Pivot File - rcd_acc_act \n",
    "rcd_acc_act = PivotCsv(srcDir, 'rcd_acc_act.csv',['pct'],'agency_code', ['subject','subgroup'],'_ACT')\n",
    "rcd_acc_act.columns = [i.lower() for i in rcd_acc_act.columns]\n",
    "\n",
    "# Pivot File - rcd_acc_awa \n",
    "rcd_acc_awa = PivotCsv(srcDir, 'rcd_acc_awa.csv',['pct'],'agency_code', ['subgroup'],'_awa')\n",
    "rcd_acc_awa.columns = [i.lower() for i in rcd_acc_awa.columns]\n",
    "\n",
    "# Pivot File - rcd_acc_cgr\n",
    "rcd_acc_cgr = PivotCsv(srcDir, 'rcd_acc_cgr.csv',['pct'],'agency_code', ['cgr_type', 'subgroup'],'_CGR')\n",
    "rcd_acc_cgr.columns = [i.lower() for i in rcd_acc_cgr.columns]\n",
    "\n",
    "# File - rcd_acc_eds\n",
    "rcd_acc_eds = pd.read_csv(srcDir + 'rcd_acc_eds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_eds = rcd_acc_eds[['agency_code', 'pct_eds']]\n",
    "rcd_acc_eds.columns = [i.lower() for i in rcd_acc_eds.columns]\n",
    "\n",
    "# File - rcd_acc_eg.csv\n",
    "pivVals = ['eg_status','eg_index','eg_score']\n",
    "rcd_acc_eg = PivotCsv(srcDir, 'rcd_acc_eg.csv',pivVals,'agency_code', ['subject','subgroup'],'_EG')\n",
    "rcd_acc_eg.columns = [i.lower() for i in rcd_acc_eg.columns]\n",
    "\n",
    "# Pivot File - rcd_acc_elp\n",
    "rcd_acc_elp = PivotCsv(srcDir, 'rcd_acc_elp.csv',['pct', 'den'],'agency_code', ['subgroup'],'_ELP')\n",
    "rcd_acc_elp.columns = [i.lower() for i in rcd_acc_elp.columns]\n",
    "\n",
    "# File - rcd_acc_essa_desig\n",
    "rcd_acc_essa_desig = pd.read_csv(srcDir + 'rcd_acc_essa_desig.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_essa_desig.drop(['year'], axis=1, inplace=True)\n",
    "rcd_acc_essa_desig.columns = ['agency_code'] + [i.lower() + '_esea_desig' for i in rcd_acc_essa_desig.columns if i != 'agency_code']\n",
    "\n",
    "# File - rcd_acc_gp\n",
    "rcd_acc_gp = pd.read_csv(srcDir + 'rcd_acc_gp.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_gp.drop(['year'], axis=1, inplace=True)\n",
    "rcd_acc_gp.columns = ['agency_code'] + [i.lower() + '_GP' for i in rcd_acc_gp.columns if i != 'agency_code']\n",
    "\n",
    "# Pivot File - rcd_acc_irm\n",
    "rcd_acc_irm = PivotCsv(srcDir, 'rcd_acc_irm.csv',['pct_prof'],'agency_code', ['grade'],'gr_irm')\n",
    "rcd_acc_irm.columns = [i.lower() for i in rcd_acc_irm.columns]\n",
    "\n",
    "# File - rcd_acc_lowperf\n",
    "rcd_acc_lowperf = pd.read_csv(srcDir + 'rcd_acc_lowperf.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_lowperf = rcd_acc_lowperf[['agency_code', 'lp_school','rlp_school','clpc_school']]\n",
    "rcd_acc_lowperf.columns = ['agency_code'] + [i.lower() +  '_lowperf' for i in rcd_acc_lowperf.columns if i != 'agency_code']\n",
    "\n",
    "# Pivot File - rcd_acc_ltg\n",
    "rcd_acc_ltg = PivotCsv(srcDir, 'rcd_acc_ltg.csv',['pct_met','target_met','target_assign'],'agency_code', ['target'],'_LTG')\n",
    "rcd_acc_ltg.columns = [i.lower() for i in rcd_acc_ltg.columns]\n",
    "\n",
    "# File - rcd_acc_ltg_detail\n",
    "rcd_acc_ltg_detail = pd.read_csv(srcDir + 'rcd_acc_ltg_detail.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_ltg_detail.drop(['year'], axis=1, inplace=True)\n",
    "rcd_acc_ltg_detail.columns = ['agency_code'] + [i.lower() + '_ltg_detail' for i in rcd_acc_ltg_detail.columns if i != 'agency_code']\n",
    "\n",
    "# Pivot File - rcd_acc_mcr\n",
    "rcd_acc_mcr = PivotCsv(srcDir, 'rcd_acc_mcr.csv',['pct'],'agency_code', ['subgroup'],'_MCR')\n",
    "rcd_acc_mcr.columns = [i.lower() for i in rcd_acc_mcr.columns]\n",
    "\n",
    "# Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_part = PivotCsv(srcDir, 'rcd_acc_part.csv',['pct_met','target_met','target_assign'],'agency_code', ['target'],'_PART')\n",
    "rcd_acc_part.columns = [i.lower() for i in rcd_acc_part.columns]\n",
    "\n",
    "# Pivot File - rcd_acc_part\n",
    "rcd_acc_part_detail = PivotCsv(srcDir, 'rcd_acc_part_detail.csv',['pct'],'agency_code', ['target','subgroup'],'_PART_DET')\n",
    "rcd_acc_part_detail.columns = [i.lower() for i in rcd_acc_part_detail.columns]\n",
    "\n",
    "# Pivot File - rcd_acc_pc - WARNING 3323 columns!!!\n",
    "rcd_acc_pc = PivotCsv(srcDir, 'rcd_acc_pc.csv',['pct'],'agency_code', ['standard','subject','grade','subgroup'],'_PC')\n",
    "rcd_acc_pc.columns = [i.lower() for i in rcd_acc_pc.columns]\n",
    "\n",
    "# Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_rta = PivotCsv(srcDir, 'rcd_acc_rta.csv',['pct'],'agency_code', ['metric'],'_RTA')\n",
    "rcd_acc_rta.columns = [i.lower() for i in rcd_acc_rta.columns]\n",
    "\n",
    "# File - rcd_acc_spg1 - Appears retired - 2017 data\n",
    "#rcd_acc_spg1 = pd.read_csv(srcDir + 'rcd_acc_spg1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_acc_spg1.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "# File - rcd_acc_spg2\n",
    "pivVals = ['asm_option','k2_feeder','aaa_score','awa_score','cgrs_score','elp_score',\n",
    "           'mcr_score','scgs_score','bi_score','ach_score','eg_status','eg_score',\n",
    "           'spg_score','spg_grade','mags_score','ma_eg_status','ma_eg_score',\n",
    "           'ma_spg_score','ma_spg_grade','rdgs_score','rd_eg_status','rd_eg_score',\n",
    "           'rd_spg_score','rd_spg_grade']\n",
    "rcd_acc_spg2 = PivotCsv(srcDir, 'rcd_acc_spg2.csv',pivVals,'agency_code', ['subgroup'],'_SPG2')\n",
    "rcd_acc_spg2.columns = [i.lower() for i in rcd_acc_spg2.columns]\n",
    "\n",
    "# Pivot File - rcd_acc_wk\n",
    "rcd_acc_wk = PivotCsv(srcDir, 'rcd_acc_wk.csv',['pct'],'agency_code', ['subgroup'],'_WK')\n",
    "rcd_acc_wk.columns = [i.lower() for i in rcd_acc_wk.columns]\n",
    "\n",
    "# File - rcd_adm\n",
    "rcd_adm = pd.read_csv(srcDir + 'rcd_adm.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_adm.drop(['year','category_code'], axis=1, inplace=True)\n",
    "rcd_adm.columns = ['agency_code'] + [i.lower() + '_adm' for i in rcd_adm.columns if i != 'agency_code']\n",
    "\n",
    "# File - rcd_ap\n",
    "rcd_ap = pd.read_csv(srcDir + 'rcd_ap.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ap.drop(['year','category_code'], axis=1, inplace=True)\n",
    "rcd_ap.columns = ['agency_code'] + [i.lower() + '_ap' for i in rcd_ap.columns if i != 'agency_code']\n",
    "\n",
    "# File - rcd_arts \n",
    "rcd_arts = pd.read_csv(srcDir + 'rcd_arts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_arts.drop(['year'], axis=1, inplace=True)\n",
    "rcd_arts.columns = ['agency_code'] + [i.lower() + '_arts' for i in rcd_arts.columns if i != 'agency_code']\n",
    "\n",
    "# File - rcd_att - retired\n",
    "#rcd_att = pd.read_csv(srcDir + 'rcd_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "#rcd_att.columns = [i.lower() + '_adm_att' for i in rcd_att.columns]\n",
    "\n",
    "# Pivot File - rcd_charter\n",
    "rcd_charter = PivotCsv(srcDir, 'rcd_charter.csv',['pct_enrolled'],'agency_code', ['subgroup'],'_CHARTER')\n",
    "rcd_charter.columns = [i.lower() for i in rcd_charter.columns]\n",
    "\n",
    "# Pivot File - rcd_chronic_absent\n",
    "rcd_chronic_absent = PivotCsv(srcDir, 'rcd_chronic_absent.csv',['pct', 'Count'],'agency_code', ['subgroup'],'_CHRON_ABSENT')\n",
    "rcd_chronic_absent.columns = [i.lower() for i in rcd_chronic_absent.columns]\n",
    "\n",
    "# Pivot File - rcd_college \n",
    "rcd_college = PivotCsv(srcDir, 'rcd_college.csv',['pct_enrolled', 'count'],'agency_code', \n",
    "                       ['graduation_year','Status','subgroup'],'_COLLEGE')\n",
    "rcd_college.columns = [i.lower() for i in rcd_college.columns]\n",
    "\n",
    "# File - rcd_courses1 - Appears retired - 2017 DATA \n",
    "# Found 0 duplicate agency_codes in this file, no pivot \n",
    "# rcd_courses1 = pd.read_csv(srcDir + 'rcd_courses1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "# rcd_courses1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "# Pivot File - rcd_courses2\n",
    "pivCols = ['tot_num_ap','subgroup','pct_ap','tot_num_ccp','pct_ccp','tot_num_ib','pct_ib']\n",
    "rcd_courses2 = PivotCsv(srcDir, 'rcd_courses2.csv',pivCols,'agency_code', \n",
    "                        ['category_code','subgroup'],'_COURSES2')\n",
    "rcd_courses2.columns = [i.lower() for i in rcd_courses2.columns]\n",
    "\n",
    "# Pivot File - rcd_cte_concentrators\n",
    "rcd_cte_concentrators = PivotCsv(srcDir, 'rcd_cte_concentrators.csv',['num_concentrators'],'agency_code',\n",
    "                                 ['career_cluster'],'_CTE_CON')\n",
    "rcd_cte_concentrators.columns = [i.lower() for i in rcd_cte_concentrators.columns]\n",
    "\n",
    "# File - rcd_cte_credentials\n",
    "rcd_cte_credentials = pd.read_csv(srcDir + 'rcd_cte_credentials.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_credentials.drop(['year'], axis=1, inplace=True)\n",
    "rcd_cte_credentials.columns = ['agency_code'] + [i.lower() + '_cte_cred' for i in rcd_cte_credentials.columns if i != 'agency_code']\n",
    "\n",
    "# File - rcd_cte_endorsement\n",
    "rcd_cte_endorsement = pd.read_csv(srcDir + 'rcd_cte_endorsement.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_endorsement.drop(['year'], axis=1, inplace=True)\n",
    "rcd_cte_endorsement.columns = ['agency_code'] + [i.lower() + '_cte_end' for i in rcd_cte_endorsement.columns if i != 'agency_code']\n",
    "\n",
    "# File - rcd_cte_enrollment\n",
    "rcd_cte_enrollment = pd.read_csv(srcDir + 'rcd_cte_enrollment.csv', low_memory=False, dtype={'agency_code': object}) \n",
    "rcd_cte_enrollment.drop(['year'], axis=1, inplace=True)\n",
    "rcd_cte_endorsement.columns = ['agency_code'] + [i.lower() + '_cte_enroll' for i in rcd_cte_endorsement.columns if i != 'agency_code']\n",
    "\n",
    "# File - rcd_dlmi\n",
    "rcd_dlmi = pd.read_csv(srcDir + 'rcd_dlmi.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_dlmi.drop(['year'], axis=1, inplace=True)\n",
    "rcd_dlmi.columns = ['agency_code'] + [i.lower() + '_dlmi' for i in rcd_dlmi.columns if i != 'agency_code']\n",
    "\n",
    "# Pivot File - rcd_effectiveness - Appears retired - 2017 Data\n",
    "# rcd_effectiveness = PivotCsv(srcDir, 'rcd_effectiveness.csv',['pct_rating'],'agency_code', ['ee_standard','ee_rating'],'')\n",
    "\n",
    "# File - rcd_effectiveness3 \n",
    "rcd_effectiveness3 = pd.read_csv(srcDir + 'rcd_effectiveness3.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_effectiveness3.drop(['year','category_code'], axis=1, inplace=True)\n",
    "rcd_effectiveness3.columns = ['agency_code'] + [i.lower() + '_effect3' for i in rcd_effectiveness3.columns if i != 'agency_code']\n",
    "\n",
    "#File - rcd_esea_att - Appears Retired - 2015 DATA\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "#rcd_esea_att = pd.read_csv(srcDir + 'rcd_esea_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_esea_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "# File - rcd_eq - New for 2019\n",
    "rcd_eq = pd.read_csv(srcDir + 'rcd_eq.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_eq.drop(['year'], axis=1, inplace=True)\n",
    "rcd_eq.columns = ['agency_code'] + [i.lower() + '_eq' for i in rcd_eq.columns if i != 'agency_code']\n",
    "\n",
    "#Pivot File - rcd_experience- Retired - 2018 Data\n",
    "#expPivColumns = ['pct_experience_0','pct_experience_10','pct_experience_4',\n",
    "#                 'pct_adv_degree','pct_turnover','total_class_teach','avg_class_teach']\n",
    "#rcd_experience = PivotCsv(srcDir, 'rcd_experience.csv',expPivColumns,'agency_code', ['staff'],'Exp')\n",
    "#rcd_experience.columns = [i.lower() for i in rcd_experience.columns]\n",
    "\n",
    "#File - !!!DISTRICT LEVEL DATA!!! - Retired - 2018 Data\n",
    "#rcd_funds = pd.read_csv(srcDir + 'rcd_funds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_funds.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_funds2\n",
    "pivColumns = ['state_funds','federal_funds','local_funds','total_funds',\n",
    "              'state_ppe','federal_ppe','local_ppe','total_ppe','ADM']\n",
    "\n",
    "rcd_funds2 = PivotCsv(srcDir, 'rcd_funds2.csv',pivColumns,'agency_code', ['expenditure_category'],'funds2')\n",
    "rcd_funds2.columns = [i.lower() for i in rcd_funds2.columns]\n",
    "\n",
    "#Pivot File - rcd_hqt - Appears retired - 2016 DATA \n",
    "#rcd_hqt = PivotCsv(srcDir, 'rcd_hqt.csv',['highqual_class_pct'],'agency_code', ['category_code'],'')\n",
    "\n",
    "#File - rcd_ib \n",
    "rcd_ib = pd.read_csv(srcDir + 'rcd_ib.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ib.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_improvement - Appears retired - 2018 data\n",
    "#rcd_improvement = PivotCsv(srcDir, 'rcd_improvement.csv',['amount'],'agency_code', ['strategy'],'_Improve_Amt')\n",
    "\n",
    "# File rcd_improvement2\n",
    "rcd_improvement2 = pd.read_csv(srcDir + 'rcd_improvement2.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_improvement2.drop(['year','category_code'], axis=1, inplace=True)\n",
    "rcd_improvement2.columns = ['agency_code'] + [i.lower() + '_improvement' for i in rcd_improvement2.columns if i != 'agency_code']\n",
    "\n",
    "#File - rcd_inc1 - Appears Retired - 2017 data\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "#rcd_inc1 = pd.read_csv(srcDir + 'rcd_inc1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_inc1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_inc2\n",
    "inc2_piv_columns = ['iss_per1000','sts_per1000','lts_per1000','exp_per1000','act_per1000',\n",
    "                   'bha_per1000','rpt_per1000','arr_per1000']\n",
    "rcd_inc2 = PivotCsv(srcDir, 'rcd_inc2.csv',inc2_piv_columns,'agency_code', ['subgroup'],'_INC2') \n",
    "rcd_inc2.columns = [i.lower() for i in rcd_inc2.columns]\n",
    "\n",
    "# File - rcd_inc1 - Retired \n",
    "#pivFields = ['iss_per1000','sts_per1000','lts_per1000',\n",
    "#             'exp_per1000','act_per1000','bha_per1000',\n",
    "#             'rpt_per1000','arr_per1000']\n",
    "#rcd_inc = PivotCsv(srcDir, 'rcd_inc.csv',pivFields,'agency_code', ['subgroup'],'')\n",
    "\n",
    "#File - rcd_licenses  - Retired\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "#rcd_licenses = pd.read_csv(srcDir + 'rcd_licenses.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_licenses.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_location \n",
    "rcd_location = pd.read_csv(srcDir + 'rcd_location.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_location.drop(['year'], axis=1, inplace=True)\n",
    "rcd_location.columns = ['agency_code'] + [i.lower() + '_loc' for i in rcd_location.columns if i != 'agency_code']\n",
    "\n",
    "#Pivot File - rcd_naep !!!NATIONAL LEVEL DATA ONLY!!!\n",
    "#pivCols = ['grade','naep_subject','subgroup','Proficiency_level']\n",
    "#rcd_naep = PivotCsv(srcDir, 'rcd_naep.csv',['percent_proficient'],'agency_code', pivCols,'_NAEP')\n",
    "\n",
    "#File - rcd_nbpts - Retired\n",
    "#rcd_nbpts = pd.read_csv(srcDir + 'rcd_nbpts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_nbpts.drop(['year','category_code','total_nbpts_num'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_pk_enroll\n",
    "rcd_pk_enroll = PivotCsv(srcDir, 'rcd_pk_enroll.csv',['pct', 'count'],'agency_code', ['subgroup'],'_PK_ENROLL')\n",
    "\n",
    "#Pivot File - rcd_prin_demo -  Empty file for 2019\n",
    "#rcd_prin_demo = PivotCsv(srcDir, 'rcd_prin_demo.csv',['pct_prin_demo'],'agency_code', ['subgroup'],'')\n",
    "\n",
    "#File - rcd_readiness\n",
    "rcd_readiness = pd.read_csv(srcDir + 'rcd_readiness.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_readiness.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_sar - Missing in 2019\n",
    "rcd_sar = PivotCsv(srcDir, 'rcd_sar.csv',['avg_size'],'agency_code', ['grade_eoc'],'_SAR')\n",
    "rcd_sar.columns = [i.lower() for i in rcd_sar.columns]\n",
    "\n",
    "#File - rcd_sat\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_sat = pd.read_csv(srcDir + 'rcd_sat.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_sat.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_welcome\n",
    "rcd_welcome = pd.read_csv(srcDir + 'rcd_welcome.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_welcome.drop(['year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and display a list of all .csv file names for 2019 download\n",
    "rcdFiles = glob.glob(srcDir  + 'rcd*.csv')\n",
    "\n",
    "rcdFileNames = [os.path.splitext(ntpath.basename(x))[0] for x in rcdFiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save All Flattened Files to \\\\Raw Datasets Directory\n",
    "**This code saves all the flattened file versions as .csv files in \\\\Raw Datasets\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Flattened Versions and Record Counts for the Following Raw Data Files: \n",
      "\n",
      "rcd_acc_aapart, 56\n",
      "rcd_acc_act, 627\n",
      "rcd_acc_awa, 583\n",
      "rcd_acc_cgr, 627\n",
      "rcd_acc_eds, 2654\n",
      "rcd_acc_eg, 2548\n",
      "rcd_acc_elp, 1774\n",
      "rcd_acc_essa_desig, 2654\n",
      "rcd_acc_gp, 596\n",
      "rcd_acc_irm, 1278\n",
      "rcd_acc_lowperf, 2654\n",
      "rcd_acc_ltg, 2525\n",
      "rcd_acc_ltg_detail, 2665\n",
      "rcd_acc_mcr, 610\n",
      "rcd_acc_part, 2537\n",
      "rcd_acc_part_detail, 2537\n",
      "rcd_acc_pc, 2596\n",
      "rcd_acc_rta, 1462\n",
      "rcd_acc_spg2, 2543\n",
      "rcd_acc_wk, 404\n",
      "rcd_adm, 2647\n",
      "rcd_ap, 468\n",
      "rcd_arts, 2504\n",
      "rcd_charter, 270\n",
      "rcd_chronic_absent, 2612\n",
      "rcd_college, 602\n",
      "rcd_courses2, 658\n",
      "rcd_cte_concentrators, 553\n",
      "rcd_cte_credentials, 533\n",
      "rcd_cte_endorsement, 529\n",
      "rcd_cte_enrollment, 1189\n",
      "rcd_dlmi, 2698\n",
      "rcd_effectiveness3, 2623\n",
      "rcd_eq, 2659\n",
      "rcd_funds2, 2456\n",
      "rcd_ib, 30\n",
      "rcd_improvement2, 109\n",
      "rcd_inc2, 2602\n",
      "rcd_location, 2702\n",
      "rcd_pk_enroll, 889\n",
      "rcd_readiness, 1308\n",
      "rcd_sar, 2542\n",
      "rcd_sat, 578\n",
      "rcd_welcome, 1171\n"
     ]
    }
   ],
   "source": [
    "print('Saving Flattened Versions and Record Counts for the Following Raw Data Files: \\n')\n",
    "for fileName in rcdFileNames:\n",
    "    eval(fileName).to_csv(dataDir + 'Flattened Datasets/' + fileName + '.csv', sep=',', index=False)\n",
    "    print(fileName + ', ' + str(len(eval(fileName).index)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save Copy of the Original Statistical Profiles Data\n",
    "\n",
    "## -----------------  Manual Download Required!!! -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical Profiles - Student Body Racial Compositions at the School Level\n",
    "#import io\n",
    "#import requests\n",
    "\n",
    "#url='http://apps.schools.nc.gov/ords/f?p=145:221::CSV::::'\n",
    "statProfPath = dataDir + 'SRC_Datasets/' + 'ec_pupils.csv'\n",
    "\n",
    "#Passing this URL directly into pd.read_csv() threw HTTP errors - This is my workaround\n",
    "#s = requests.get(url).content\n",
    "#ec_pupils = pd.read_csv(io.StringIO(s.decode('utf-8')), low_memory=False\n",
    "#                        , dtype={'LEA': object,'School': object})\n",
    "\n",
    "ec_pupils = pd.read_csv(statProfPath, low_memory=False\n",
    "                        , dtype={'LEA': object,'School': object})\n",
    "\n",
    "#Rename year for consistency\n",
    "ec_pupils.rename({'Year':'year', '____LEA Name____':'LEA Name', '___School Name___':'school name',\n",
    "                 'Two or  More Male':'two or more male', 'Two or  More Female':'two or more female'}, axis=1, inplace=True)\n",
    "\n",
    "#Create agency_code from LEA and School code as an index\n",
    "ec_pupils['agency_code'] = ec_pupils['LEA'] + ec_pupils['School']\n",
    "\n",
    "#Filter to 2018 school year (There is already 2019 school year data in this file)\n",
    "#ec_pupils = ec_pupils[ec_pupils.year == schoolYear]\n",
    "\n",
    "#Some schools are missing race data.  Get the most recent year of data available for each agency code\n",
    "ec_pupils = ec_pupils.sort_values(by=['agency_code', 'year'])\n",
    "ec_pupils = ec_pupils.drop_duplicates(subset=[\"agency_code\"], keep=\"last\")\n",
    "\n",
    "ec_pupils.columns = [i.lower() for i in ec_pupils.columns]\n",
    "\n",
    "#Save the original data to the source datasets folder \n",
    "ec_pupils.to_csv(statProfPath, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flattened Statistical Profiles with Racial Composition Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Flattened Versions and Record Counts for the Following Raw Data Files: \n",
      "\n",
      "ec_pupils_pct, 2504\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "# Statistical Profiles - Student Body Racial Compositions at the School Level Reshape\n",
    "#\n",
    "# Statistical Profiles data are already one record per public school but must be converted to percentages\n",
    "# Creates a new dataset - ec_pupils_pct.csv\n",
    "#\n",
    "#***********************************************************************\n",
    "\n",
    "#Statistical Profiles - Student Body Racial Compositions at the School Level\n",
    "ec_pupils = pd.read_csv(statProfPath, low_memory=False, dtype={'agency_code': object})\n",
    "\n",
    "#Create Racial Composition summary variables\n",
    "ec_pupils['indian'] = ec_pupils['indian male'] + ec_pupils['indian female']\n",
    "ec_pupils['asian'] = ec_pupils['asian male'] + ec_pupils['asian female']\n",
    "ec_pupils['hispanic'] = ec_pupils['hispanic male'] + ec_pupils['hispanic female']\n",
    "ec_pupils['black'] = ec_pupils['black male'] + ec_pupils['black female']\n",
    "ec_pupils['white'] = ec_pupils['white male'] + ec_pupils['white female']\n",
    "ec_pupils['pacific island'] = ec_pupils['pacific island male'] + ec_pupils['pacific island female']\n",
    "ec_pupils['two or more'] = ec_pupils['two or more male'] + ec_pupils['two or more female']\n",
    "\n",
    "#The original total field is corrupted with non-printable characters and will not convert to int or float \n",
    "ec_pupils.drop(['total'], axis=1, inplace=True)\n",
    "#Create a new totals field by summing race composition fields\n",
    "ec_pupils['total'] = ec_pupils['indian'] + ec_pupils['asian'] + \\\n",
    "                     ec_pupils['hispanic'] + ec_pupils['black'] + \\\n",
    "                     ec_pupils['white'] + ec_pupils['pacific island'] + ec_pupils['two or more']\n",
    "#Convert totals to float64 for division later\n",
    "ec_pupils['total'] = ec_pupils['total'].astype(np.float64)\n",
    "\n",
    "#Create minority summary variables \n",
    "ec_pupils['minority male'] = ec_pupils['indian male'] + ec_pupils['asian male'] \\\n",
    "                           + ec_pupils['hispanic male'] + ec_pupils['black male'] \\\n",
    "                           + ec_pupils['pacific island male'] + ec_pupils['two or more male'] \n",
    "ec_pupils['minority female'] = ec_pupils['indian female'] + ec_pupils['asian female'] \\\n",
    "                           + ec_pupils['hispanic female'] + ec_pupils['black female'] \\\n",
    "                           + ec_pupils['pacific island female'] + ec_pupils['two or more female']\n",
    "ec_pupils['minority'] = ec_pupils['minority male'] + ec_pupils['minority female']\n",
    "\n",
    "#Create Student Body Racial Composition PERCENTAGES at the School Level\n",
    "ec_pupils_pct = pd.DataFrame({'agency_code'   : ec_pupils['agency_code']\n",
    "                            , 'lea' : ec_pupils['lea']\n",
    "                            , 'lea_name' : ec_pupils['lea name']\n",
    "                            , 'school' : ec_pupils['school']\n",
    "                            , 'school_name' : ec_pupils['school name']\n",
    "                            , 'indian_pct'   : ec_pupils['indian'] / ec_pupils['total']  \n",
    "                            , 'asian_pct'    : ec_pupils['asian'] / ec_pupils['total']\n",
    "                            , 'hispanic_pct' : ec_pupils['hispanic'] / ec_pupils['total']\n",
    "                            , 'black_pct'    : ec_pupils['black'] / ec_pupils['total']\n",
    "                            , 'white_pct'    : ec_pupils['white'] / ec_pupils['total']\n",
    "                            , 'pacific_Island_pct': ec_pupils['pacific island'] / ec_pupils['total']\n",
    "                            , 'two_or_more_pct': ec_pupils['two or more'] / ec_pupils['total']\n",
    "                            , 'minority_pct' : ec_pupils['minority'] / ec_pupils['total']\n",
    "                            \n",
    "                              \n",
    "                            , 'indian_male_pct'   : ec_pupils['indian male'] / ec_pupils['total']  \n",
    "                            , 'asian_male_pct'    : ec_pupils['asian male'] / ec_pupils['total']\n",
    "                            , 'hispanic_male_pct' : ec_pupils['hispanic male'] / ec_pupils['total']\n",
    "                            , 'black_male_pct'    : ec_pupils['black male'] / ec_pupils['total']\n",
    "                            , 'white_male_pct'    : ec_pupils['white male'] / ec_pupils['total']\n",
    "                            , 'pacific_Island_male_pct': ec_pupils['pacific island male'] / ec_pupils['total']\n",
    "                            , 'two_or_more_male_pct': ec_pupils['two or more male'] / ec_pupils['total']  \n",
    "                            , 'minority_male_pct' : ec_pupils['minority male'] / ec_pupils['total']\n",
    "                                                          \n",
    "                            , 'indian_female_pct'   : ec_pupils['indian female'] / ec_pupils['total']  \n",
    "                            , 'asian_female_pct'    : ec_pupils['asian female'] / ec_pupils['total']\n",
    "                            , 'hispanic_female_pct' : ec_pupils['hispanic female'] / ec_pupils['total']\n",
    "                            , 'black_female_pct'    : ec_pupils['black female'] / ec_pupils['total']\n",
    "                            , 'white_female_pct'    : ec_pupils['white female'] / ec_pupils['total']\n",
    "                            , 'minority_female_pct' : ec_pupils['minority female'] / ec_pupils['total'] \n",
    "                            , 'pacific_Island_female_pct': ec_pupils['pacific island female'] / ec_pupils['total']\n",
    "                            , 'two_or_more_female_pct': ec_pupils['two or more female'] / ec_pupils['total']\n",
    "                             })\n",
    "\n",
    "ec_pupils_pct.columns = [i.lower() for i in ec_pupils_pct.columns]\n",
    "\n",
    "#Save the flattened racial composition percentage data to disk \n",
    "ec_pupils_pct.to_csv(dataDir + 'Flattened Datasets/' + 'ec_pupils_pct.csv', sep=',', index=False)\n",
    "\n",
    "#Print file details\n",
    "print('Saving Flattened Versions and Record Counts for the Following Raw Data Files: \\n')\n",
    "print('ec_pupils_pct' + ', ' + str(len(ec_pupils_pct.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
