{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create NCDPI 2017-2018 Raw Datasets\n",
    "### This program downloads all original datasets from www.ncpublicschools.org and saves them as .csv files. These data files are used to create all the flattened and machine learning datasets within the NCEA repository.\n",
    "\n",
    "1. This notebook downloads raw datasets directly from NCDPI specific URLs.\n",
    "2. Each raw dataset is filtered by school year and saved in the original layout as a .csv file.\n",
    "3. For consistency, both the Year and School code fields are renamed to \"year\" and \"agency_code\" in all files.\n",
    "4. All masking is removed from raw data fields using the following code: replace({\"*\":0, \">95\":100, \"<5\":0, \"<10\":5 })\n",
    "5. All * or carriage returns are removed from column names.\n",
    "6. All raw datasets created by this program are used to create the \"flattened\" and \"machine learning\" Public School datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to add the correct packages path to your jupyter enviroment, if it is missing. \n",
    "#import sys\n",
    "#sys.path.append('C:/Users/Jake/Anaconda2/envs/example_env/Lib/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#**********************************************************************************\n",
    "# Set the following variables before running this code!!!\n",
    "#**********************************************************************************\n",
    "\n",
    "#Location where copies of the raw data files will be downloaded and saved as csv files.\n",
    "dataDir = 'D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/June 2020/2018/Raw Datasets/'\n",
    "\n",
    "#All raw data files are filtered for the year below\n",
    "schoolYear = 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save Copy of the Original SRC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "#Download and save an original copy of the raw SRC data \n",
    "url=\"http://www.ncpublicschools.org/docs/src/researchers/src-datasets.zip\"\n",
    "zipFilePath = dataDir + 'src-datasets.zip'\n",
    "\n",
    "#Comment out the next line after downloading the original data one time! \n",
    "#urllib.request.urlretrieve(url, zipFilePath)\n",
    "\n",
    "import zipfile\n",
    "\n",
    "#Extract the zip file and all school datasets to the //Raw Datasets/ folder\n",
    "zip_ref = zipfile.ZipFile(zipFilePath, 'r')\n",
    "zip_ref.extractall(dataDir)\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on rcd_effectiveness.csv, Max Year: 2017\n",
    "* The rcd_effectiveness.csv file for 2017-18 only had data up to 2017.  \n",
    "* When the 2018-19 file was published, it had the data for 2017-18 as well. \n",
    "* So I moved the file with the correct data from 2018-19 to 2017-18 and republished all of the school and ML data files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on rcd_college.csv, Max Year: 2017\n",
    "* The rcd_college.csv file for 2017-18 only had data up to 2017.  \n",
    "* When the 2018-19 file was published, it had data for 2017-18 as well. \n",
    "* So I moved the file with the correct data from 2018-19 to 2017-18 and republished all of the school and ML data files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Most Recent Year of Data from Each File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataDir path for this part\n",
    "dataDir = dataDir + 'SRC_Datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use ntpath.basename to get a filename from a filepath\n",
    "import ntpath\n",
    "\n",
    "def CleanUpRcdFiles(filePath):\n",
    "    fileName = ntpath.basename(filePath)\n",
    "    schFile = pd.read_csv(filePath, dtype={'agency_code': object}, low_memory=False)\n",
    "    maxYear = schFile['year'].max()\n",
    "    \n",
    "    #Filter records for the most recent year\n",
    "    schFile = schFile[schFile['year'] == maxYear]\n",
    "    \n",
    "    #Remove state and district level summary records \n",
    "    #schFile = schFile[(schFile['agency_code'] != 'NC-SEA') & (schFile['agency_code'].str.contains(\"LEA\") == False)]\n",
    "        \n",
    "    #Remove * character from any fields. \n",
    "    schFile = schFile.replace({'*':''})\n",
    "    schFile.to_csv(dataDir + fileName, sep=',', index=False)\n",
    "    \n",
    "    print(fileName + ', Max Year: ' + str(maxYear))\n",
    "    return (fileName, maxYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Files to: D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/June 2020/2018/Raw Datasets/SRC_Datasets/\n",
      "\n",
      "rcd_161.csv, Max Year: 2012\n",
      "rcd_acc_aapart.csv, Max Year: 2018\n",
      "rcd_acc_act.csv, Max Year: 2018\n",
      "rcd_acc_awa.csv, Max Year: 2018\n",
      "rcd_acc_cgr.csv, Max Year: 2018\n",
      "rcd_acc_eds.csv, Max Year: 2018\n",
      "rcd_acc_elp.csv, Max Year: 2018\n",
      "rcd_acc_essa_desig.csv, Max Year: 2018\n",
      "rcd_acc_gp.csv, Max Year: 2018\n",
      "rcd_acc_irm.csv, Max Year: 2018\n",
      "rcd_acc_lowperf.csv, Max Year: 2018\n",
      "rcd_acc_ltg.csv, Max Year: 2018\n",
      "rcd_acc_ltg_detail.csv, Max Year: 2018\n",
      "rcd_acc_mcr.csv, Max Year: 2018\n",
      "rcd_acc_part.csv, Max Year: 2018\n",
      "rcd_acc_part_detail.csv, Max Year: 2018\n",
      "rcd_acc_pc.csv, Max Year: 2018\n",
      "rcd_acc_rta.csv, Max Year: 2018\n",
      "rcd_acc_spg1.csv, Max Year: 2017\n",
      "rcd_acc_spg2.csv, Max Year: 2018\n",
      "rcd_acc_wk.csv, Max Year: 2018\n",
      "rcd_adm.csv, Max Year: 2018\n",
      "rcd_ap.csv, Max Year: 2018\n",
      "rcd_arts.csv, Max Year: 2018\n",
      "rcd_att.csv, Max Year: 2018\n",
      "rcd_charter.csv, Max Year: 2018\n",
      "rcd_chronic_absent.csv, Max Year: 2018.0\n",
      "rcd_college.csv, Max Year: 2018\n",
      "rcd_courses1.csv, Max Year: 2017\n",
      "rcd_courses2.csv, Max Year: 2018\n",
      "rcd_cte_concentrators.csv, Max Year: 2018\n",
      "rcd_cte_credentials.csv, Max Year: 2018\n",
      "rcd_cte_endorsement.csv, Max Year: 2018\n",
      "rcd_cte_enrollment.csv, Max Year: 2018\n",
      "rcd_dlmi.csv, Max Year: 2018\n",
      "rcd_effectiveness.csv, Max Year: 2018\n",
      "rcd_esea_att.csv, Max Year: 2015\n",
      "rcd_experience.csv, Max Year: 2018\n",
      "rcd_funds.csv, Max Year: 2018\n",
      "rcd_hqt.csv, Max Year: 2016\n",
      "rcd_ib.csv, Max Year: 2018\n",
      "rcd_improvement.csv, Max Year: 2018\n",
      "rcd_inc1.csv, Max Year: 2017\n",
      "rcd_inc2.csv, Max Year: 2018\n",
      "rcd_licenses.csv, Max Year: 2018\n",
      "rcd_location.csv, Max Year: 2018\n",
      "rcd_naep.csv, Max Year: 2017\n",
      "rcd_nbpts.csv, Max Year: 2018\n",
      "rcd_pk_enroll.csv, Max Year: 2018\n",
      "rcd_prin_demo.csv, Max Year: 2018\n",
      "rcd_readiness.csv, Max Year: 2018\n",
      "rcd_sar.csv, Max Year: 2018\n",
      "rcd_sat.csv, Max Year: 2018\n",
      "rcd_welcome.csv, Max Year: 2018\n"
     ]
    }
   ],
   "source": [
    "#Use wildcards to find files in a directory\n",
    "import glob\n",
    "\n",
    "#Get and display a list of all .csv file names for 2018 download\n",
    "rcdFiles = glob.glob(dataDir + 'rcd*.csv')\n",
    "\n",
    "print('Saving Files to: ' + dataDir + '\\n')\n",
    "\n",
    "file_data_years = []\n",
    "for filePth in rcdFiles:\n",
    "    fileName = ntpath.basename(filePth)\n",
    "    if fileName != 'rcd_code_desc.csv': \n",
    "        file_data_years.append(CleanUpRcdFiles(filePth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove comma from amount field in rcd_improvement\n",
    "rcd_improvement = pd.read_csv(dataDir + 'rcd_improvement.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_improvement['amount'] = rcd_improvement['amount'].astype(str).str.replace(',', '').astype(float)\n",
    "rcd_improvement.to_csv(dataDir + 'rcd_improvement.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Manually remove what appear to be retired data files\n",
    "\n",
    "# rcd_161.csv, Max Year: 2012, appears retired\n",
    "os.remove(dataDir + 'rcd_161.csv')\n",
    "# rcd_esea_att.csv, Max Year: 2015, appears retired\n",
    "os.remove(dataDir + 'rcd_esea_att.csv')\n",
    "# rcd_hqt.csv, Max Year: 2016, appears retired\n",
    "os.remove(dataDir + 'rcd_hqt.csv')\n",
    "\n",
    "# Manually remove any split data files that do not have data for the current year. \n",
    "\n",
    "# rcd_acc_spg1.csv, Max Year: 2017, rcd_acc_spg2 has 2018\n",
    "os.remove(dataDir + 'rcd_acc_spg1.csv')\n",
    "# rcd_courses1.csv, Max Year: 2017, rcd_courses2 has 2018 \n",
    "os.remove(dataDir + 'rcd_courses1.csv')\n",
    "# rcd_inc1.csv, Max Year: 2017, rcd_inc2 has 2018\n",
    "os.remove(dataDir + 'rcd_inc1.csv')\n",
    "\n",
    "# Manually remove files that do not have campus level data\n",
    "\n",
    "# rcd_neap.csv, National Data and State Only\n",
    "os.remove(dataDir + 'rcd_naep.csv')\n",
    "# rcd_prin_demo.csv, 1 column of District Level Data Only\n",
    "os.remove(dataDir + 'rcd_prin_demo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Files\n",
      "----------------------------------\n",
      "('rcd_acc_aapart.csv', 2018)\n",
      "('rcd_acc_act.csv', 2018)\n",
      "('rcd_acc_awa.csv', 2018)\n",
      "('rcd_acc_cgr.csv', 2018)\n",
      "('rcd_acc_eds.csv', 2018)\n",
      "('rcd_acc_elp.csv', 2018)\n",
      "('rcd_acc_essa_desig.csv', 2018)\n",
      "('rcd_acc_gp.csv', 2018)\n",
      "('rcd_acc_irm.csv', 2018)\n",
      "('rcd_acc_lowperf.csv', 2018)\n",
      "('rcd_acc_ltg.csv', 2018)\n",
      "('rcd_acc_ltg_detail.csv', 2018)\n",
      "('rcd_acc_mcr.csv', 2018)\n",
      "('rcd_acc_part.csv', 2018)\n",
      "('rcd_acc_part_detail.csv', 2018)\n",
      "('rcd_acc_pc.csv', 2018)\n",
      "('rcd_acc_rta.csv', 2018)\n",
      "('rcd_acc_spg2.csv', 2018)\n",
      "('rcd_acc_wk.csv', 2018)\n",
      "('rcd_adm.csv', 2018)\n",
      "('rcd_ap.csv', 2018)\n",
      "('rcd_arts.csv', 2018)\n",
      "('rcd_att.csv', 2018)\n",
      "('rcd_charter.csv', 2018)\n",
      "('rcd_chronic_absent.csv', 2018.0)\n",
      "('rcd_college.csv', 2018)\n",
      "('rcd_courses2.csv', 2018)\n",
      "('rcd_cte_concentrators.csv', 2018)\n",
      "('rcd_cte_credentials.csv', 2018)\n",
      "('rcd_cte_endorsement.csv', 2018)\n",
      "('rcd_cte_enrollment.csv', 2018)\n",
      "('rcd_dlmi.csv', 2018)\n",
      "('rcd_effectiveness.csv', 2018)\n",
      "('rcd_experience.csv', 2018)\n",
      "('rcd_funds.csv', 2018)\n",
      "('rcd_ib.csv', 2018)\n",
      "('rcd_improvement.csv', 2018)\n",
      "('rcd_inc2.csv', 2018)\n",
      "('rcd_licenses.csv', 2018)\n",
      "('rcd_location.csv', 2018)\n",
      "('rcd_nbpts.csv', 2018)\n",
      "('rcd_pk_enroll.csv', 2018)\n",
      "('rcd_readiness.csv', 2018)\n",
      "('rcd_sar.csv', 2018)\n",
      "('rcd_sat.csv', '2018')\n",
      "('rcd_welcome.csv', 2018)\n"
     ]
    }
   ],
   "source": [
    "# Update our file lists\n",
    "file_data_years = [i for i in file_data_years if i[0] not in \n",
    "                   ['rcd_161.csv','rcd_esea_att.csv','rcd_hqt.csv','rcd_acc_spg1.csv','rcd_courses1.csv',\n",
    "                    'rcd_inc1.csv','rcd_naep.csv','rcd_prin_demo.csv']]\n",
    "\n",
    "rcdFiles = glob.glob(dataDir + 'SRC_Datasets/' + 'rcd*.csv') \n",
    "\n",
    "print('Remaining Files')\n",
    "print('----------------------------------')\n",
    "\n",
    "for f in file_data_years:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flatten the Raw Data Files\n",
    "### This section reads raw data files directly from the \\\\Raw Datasets folder and flattens each file.\n",
    "1. Each agency_code could represent National, State, District, Or School Campus level data.\n",
    "2. This code creates new data columns using pivots until there is only one record per agency_code.\n",
    "3. Percentage fields are always used for pivot values in cases where count, denominators, or percentages are available.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get and display a list of all .csv file names for 2018 download\n",
    "rcdFiles = glob.glob(dataDir + 'rcd*.csv')\n",
    "\n",
    "rcdFileNames = [ntpath.basename(x)[:-4] for x in rcdFiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do not process the rcd_code_desc file  \n",
    "rcdFileNames.remove('rcd_code_desc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PivotCsv(dataDir, fileName, pivValues, pivIndex, pivColumns, colSuffix):\n",
    "    pivFile = pd.read_csv(dataDir + fileName, low_memory=False, dtype={pivIndex: object})\n",
    "    \n",
    "    pivFile = pd.pivot_table(pivFile, values=pivValues,index=pivIndex,columns=pivColumns)\n",
    "    \n",
    "    #concatenate multiindex column names using a list comprehension.\n",
    "    pivFile.columns = [ '_'.join(str(i) for i in col) + colSuffix for col in pivFile.columns]\n",
    "\n",
    "    #Make our index a column for merges later\n",
    "    pivFile.reset_index(level=0, inplace=True)\n",
    "    return pivFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot File - rcd_161 - Retired\n",
    "#rcd_161 = PivotCsv(dataDir, 'rcd_161.csv',['ccc_pct'],'agency_code', ['status','subgroup'],'_161')\n",
    "\n",
    "#Pivot File - rcd_acc_aapart \n",
    "rcd_acc_aapart = PivotCsv(dataDir, 'rcd_acc_aapart.csv',['pct'],'agency_code', ['subject','grade'],'_AAPART')\n",
    "\n",
    "#Pivot File - rcd_acc_act \n",
    "rcd_acc_act = PivotCsv(dataDir, 'rcd_acc_act.csv',['pct'],'agency_code', ['subject','subgroup'],'_ACT')\n",
    "\n",
    "#Pivot File - rcd_acc_awa \n",
    "rcd_acc_awa = PivotCsv(dataDir, 'rcd_acc_awa.csv',['pct'],'agency_code', ['subgroup'],'_AWA')\n",
    "\n",
    "#Pivot File - rcd_acc_cgr\n",
    "rcd_acc_cgr = PivotCsv(dataDir, 'rcd_acc_cgr.csv',['pct'],'agency_code', ['cgr_type', 'subgroup'],'_CGR')\n",
    "\n",
    "#File - rcd_acc_eds\n",
    "rcd_acc_eds = pd.read_csv(dataDir + 'rcd_acc_eds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_eds = rcd_acc_eds[['agency_code', 'pct_eds']]\n",
    "\n",
    "#Pivot File - rcd_acc_elp\n",
    "rcd_acc_elp = PivotCsv(dataDir, 'rcd_acc_elp.csv',['pct'],'agency_code', ['subgroup'],'_ELP')\n",
    "\n",
    "#File - rcd_acc_essa_desig\n",
    "rcd_acc_essa_desig = pd.read_csv(dataDir + 'rcd_acc_essa_desig.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_essa_desig.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_acc_gp\n",
    "rcd_acc_gp = pd.read_csv(dataDir + 'rcd_acc_gp.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_gp.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_acc_irm\n",
    "rcd_acc_irm = PivotCsv(dataDir, 'rcd_acc_irm.csv',['pct_prof'],'agency_code', ['grade'],'gr_irm')\n",
    "\n",
    "#File - rcd_acc_lowperf\n",
    "rcd_acc_lowperf = pd.read_csv(dataDir + 'rcd_acc_lowperf.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_lowperf = rcd_acc_lowperf[['agency_code', 'lp_school','rlp_school','clpc_school']]\n",
    "\n",
    "#Pivot File - rcd_acc_ltg\n",
    "rcd_acc_ltg = PivotCsv(dataDir, 'rcd_acc_ltg.csv',['pct_met'],'agency_code', ['target'],'_LTG')\n",
    "\n",
    "#File - rcd_acc_ltg_detail\n",
    "rcd_acc_ltg_detail = pd.read_csv(dataDir + 'rcd_acc_ltg_detail.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_acc_ltg_detail.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_acc_mcr\n",
    "rcd_acc_mcr = PivotCsv(dataDir, 'rcd_acc_mcr.csv',['pct'],'agency_code', ['subgroup'],'_MCR')\n",
    "\n",
    "#Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_part = PivotCsv(dataDir, 'rcd_acc_part.csv',['pct_met'],'agency_code', ['target'],'_PART')\n",
    "\n",
    "#Pivot File - rcd_acc_part\n",
    "rcd_acc_part_detail = PivotCsv(dataDir, 'rcd_acc_part_detail.csv',['pct'],'agency_code', ['target','subgroup'],'_PART_DET')\n",
    "\n",
    "#Pivot File - rcd_acc_pc - WARNING 3323 columns!!! \n",
    "rcd_acc_pc = PivotCsv(dataDir, 'rcd_acc_pc.csv',['pct'],'agency_code', ['standard','subject','grade','subgroup'],'_PC')\n",
    "\n",
    "#Pivot File - rcd_acc_part_detail\n",
    "rcd_acc_rta = PivotCsv(dataDir, 'rcd_acc_rta.csv',['pct'],'agency_code', ['metric'],'_RTA')\n",
    "\n",
    "#File - rcd_acc_spg1 _ Retired\n",
    "# rcd_acc_spg1 = pd.read_csv(dataDir + 'rcd_acc_spg1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "# rcd_acc_spg1.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_acc_spg2\n",
    "pivVals = ['asm_option','k2_feeder','aaa_score','awa_score','cgrs_score','elp_score',\n",
    "           'mcr_score','scgs_score','bi_score','ach_score','eg_status','eg_score',\n",
    "           'spg_score','spg_grade','mags_score','ma_eg_status','ma_eg_score',\n",
    "           'ma_spg_score','ma_spg_grade','rdgs_score','rd_eg_status','rd_eg_score',\n",
    "           'rd_spg_score','rd_spg_grade']\n",
    "rcd_acc_spg2 = PivotCsv(dataDir, 'rcd_acc_spg2.csv',pivVals,'agency_code', ['subgroup'],'_SPG2')\n",
    "\n",
    "#pivVals = ['aaa_score','awa_score','cgrs_score','elp_score','mcr_score','scgs_score','bi_score',\n",
    "#           'ach_score','eg_status','eg_score','spg_score','spg_grade']\n",
    "#           \n",
    "#rcd_acc_spg2 = PivotCsv(dataDir, 'rcd_acc_spg2.csv',pivVals,'agency_code', ['subgroup'],'_SPG2')\n",
    "\n",
    "#Pivot File - rcd_acc_wk\n",
    "rcd_acc_wk = PivotCsv(dataDir, 'rcd_acc_wk.csv',['pct'],'agency_code', ['subgroup'],'_WK')\n",
    "\n",
    "#File - rcd_adm\n",
    "rcd_adm = pd.read_csv(dataDir + 'rcd_adm.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_adm.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_ap\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_ap = pd.read_csv(dataDir + 'rcd_ap.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ap.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_arts\n",
    "rcd_arts = pd.read_csv(dataDir + 'rcd_arts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_arts.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_att\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "rcd_att = pd.read_csv(dataDir + 'rcd_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_charter\n",
    "#rcd_charter = PivotCsv(dataDir, 'rcd_charter.csv',['pct_enrolled'],'agency_code', ['home_lea','subgroup'],'_CHARTER')\n",
    "rcd_charter = PivotCsv(dataDir, 'rcd_charter.csv',['pct_enrolled'],'agency_code', ['subgroup'],'_CHARTER')\n",
    "\n",
    "#Pivot File - rcd_chronic_absent\n",
    "rcd_chronic_absent = PivotCsv(dataDir, 'rcd_chronic_absent.csv',['pct'],'agency_code', ['subgroup'],'_CHRON_ABSENT')\n",
    "\n",
    "#Pivot File - rcd_college\n",
    "rcd_college = PivotCsv(dataDir, 'rcd_college.csv',['pct_enrolled'],'agency_code', ['Status','subgroup'],'_COLLEGE')\n",
    "\n",
    "#File - rcd_courses1 - Retired - 2017 DATA\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "#rcd_courses1 = pd.read_csv(dataDir + 'rcd_courses1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_courses1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_courses2\n",
    "# Pivot File - rcd_courses2\n",
    "pivCols = ['tot_num_ap','subgroup','pct_ap','tot_num_ccp','pct_ccp','tot_num_ib','pct_ib']\n",
    "rcd_courses2 = PivotCsv(dataDir, 'rcd_courses2.csv',pivCols,'agency_code', \n",
    "                        ['category_code','subgroup'],'_COURSES2')\n",
    "\n",
    "#rcd_courses2 = PivotCsv(dataDir, 'rcd_courses2.csv',['pct_ap','pct_ccp','pct_ib'],'agency_code', ['category_code','subgroup'],\n",
    "#                        '_COURSES2')\n",
    "\n",
    "#Pivot File - rcd_cte_concentrators\n",
    "rcd_cte_concentrators = PivotCsv(dataDir, 'rcd_cte_concentrators.csv',['num_concentrators'],'agency_code',\n",
    "                                 ['career_cluster'],'')\n",
    "\n",
    "#File - rcd_cte_credentials\n",
    "rcd_cte_credentials = pd.read_csv(dataDir + 'rcd_cte_credentials.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_credentials.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_cte_endorsement\n",
    "rcd_cte_endorsement = pd.read_csv(dataDir + 'rcd_cte_endorsement.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_endorsement.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_cte_enrollment\n",
    "rcd_cte_enrollment = pd.read_csv(dataDir + 'rcd_cte_enrollment.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_cte_enrollment['cte_enrollment_pct'] = rcd_cte_enrollment['pct'] \n",
    "rcd_cte_enrollment.drop(['year','pct'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_dlmi\n",
    "rcd_dlmi = pd.read_csv(dataDir + 'rcd_dlmi.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_dlmi.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_effectiveness - 2017 Data\n",
    "rcd_effectiveness = PivotCsv(dataDir, 'rcd_effectiveness.csv',['pct_rating'],'agency_code', ['ee_standard','ee_rating'],'')\n",
    "\n",
    "#File - rcd_esea_att - Retired - 2015 DATA\n",
    "#Found 0 duplicate agency_codes in this file, no pivot \n",
    "#rcd_esea_att = pd.read_csv(dataDir + 'rcd_esea_att.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_esea_att.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_experience\n",
    "expPivColumns = ['pct_experience_0','pct_experience_10','pct_experience_4',\n",
    "                 'pct_adv_degree','pct_turnover','total_class_teach','avg_class_teach']\n",
    "rcd_experience = PivotCsv(dataDir, 'rcd_experience.csv',expPivColumns,'agency_code', ['staff'],'Exp')\n",
    "\n",
    "#File - !!!DISTRICT LEVEL DATA!!!\n",
    "rcd_funds = pd.read_csv(dataDir + 'rcd_funds.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_funds.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_hqt - Retired - !!!2016 DATA!!!\n",
    "# rcd_hqt = PivotCsv(dataDir, 'rcd_hqt.csv',['highqual_class_pct'],'agency_code', ['category_code'],'')\n",
    "\n",
    "#File - rcd_ib\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_ib = pd.read_csv(dataDir + 'rcd_ib.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_ib.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_improvement\n",
    "rcd_improvement = PivotCsv(dataDir, 'rcd_improvement.csv',['amount'],'agency_code', ['strategy'],'_Improve_Amt')\n",
    "\n",
    "#File - rcd_inc1 - Retired \n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "#rcd_inc1 = pd.read_csv(dataDir + 'rcd_inc1.csv', low_memory=False, dtype={'agency_code': object})\n",
    "#rcd_inc1.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_inc2 \n",
    "pivFields = ['iss_per1000','sts_per1000','lts_per1000',\n",
    "             'exp_per1000','crime_per1000','blhr_per1000',\n",
    "             'rplw_per1000','arre_per1000']\n",
    "rcd_inc2 = PivotCsv(dataDir, 'rcd_inc2.csv',pivFields,'agency_code', ['subgroup'],'')\n",
    "\n",
    "#File - rcd_licenses\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_licenses = pd.read_csv(dataDir + 'rcd_licenses.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_licenses.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_location\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_location = pd.read_csv(dataDir + 'rcd_location.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_location.drop(['year'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "#Pivot File - rcd_naep !!!NATIONAL & STATE LEVEL DATA!!!\n",
    "#pivCols = ['grade','naep_subject','subgroup','Proficiency_level']\n",
    "#rcd_naep = PivotCsv(dataDir, 'rcd_naep.csv',['percent_proficient'],'agency_code', pivCols,'_NAEP')\n",
    "\n",
    "#File - rcd_licenses\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_nbpts = pd.read_csv(dataDir + 'rcd_nbpts.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_nbpts.drop(['year','category_code','total_nbpts_num'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_pk_enroll\n",
    "rcd_pk_enroll = PivotCsv(dataDir, 'rcd_pk_enroll.csv',['pct', 'count'],'agency_code', ['subgroup'],'_PK_ENROLL')\n",
    "\n",
    "#Pivot File - rcd_prin_demo - !!! District Level Data !!!\n",
    "# rcd_prin_demo = PivotCsv(dataDir, 'rcd_prin_demo.csv',['pct_prin_demo'],'agency_code', ['subgroup'],'')\n",
    "\n",
    "#File - rcd_readiness\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_readiness = pd.read_csv(dataDir + 'rcd_readiness.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_readiness.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#Pivot File - rcd_sar\n",
    "rcd_sar = PivotCsv(dataDir, 'rcd_sar.csv',['avg_size'],'agency_code', ['grade_eoc'],'_SAR')\n",
    "\n",
    "#File - rcd_sat\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_sat = pd.read_csv(dataDir + 'rcd_sat.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_sat.drop(['year','category_code'], axis=1, inplace=True)\n",
    "\n",
    "#File - rcd_welcome\n",
    "rcd_welcome = pd.read_csv(dataDir + 'rcd_welcome.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_welcome.drop(['year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save All Flattened Files to \\\\Raw Datasets Directory\n",
    "**This code saves all the flattened file versions as .csv files in \\\\Raw Datasets\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/BenepactLLC/Belk/NC_Report_Card_Data/2020/June 2020/2018/Raw Datasets/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set dataDir back to the original value (one folder up from current location)\n",
    "import os \n",
    "dataDir = os.path.dirname(os.path.dirname(dataDir)) + '/'\n",
    "dataDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Flattened Versions and Record Counts for the Following Raw Data Files: \n",
      "\n",
      "rcd_acc_aapart, 53\n",
      "rcd_acc_act, 742\n",
      "rcd_acc_awa, 688\n",
      "rcd_acc_cgr, 738\n",
      "rcd_acc_eds, 2761\n",
      "rcd_acc_elp, 1809\n",
      "rcd_acc_essa_desig, 2645\n",
      "rcd_acc_gp, 658\n",
      "rcd_acc_irm, 1276\n",
      "rcd_acc_lowperf, 2760\n",
      "rcd_acc_ltg, 2461\n",
      "rcd_acc_ltg_detail, 2631\n",
      "rcd_acc_mcr, 717\n",
      "rcd_acc_part, 2527\n",
      "rcd_acc_part_detail, 2527\n",
      "rcd_acc_pc, 2697\n",
      "rcd_acc_rta, 1576\n",
      "rcd_acc_spg2, 2538\n",
      "rcd_acc_wk, 517\n",
      "rcd_adm, 3197\n",
      "rcd_ap, 563\n",
      "rcd_arts, 2509\n",
      "rcd_att, 3115\n",
      "rcd_charter, 241\n",
      "rcd_chronic_absent, 2719\n",
      "rcd_college, 690\n",
      "rcd_courses2, 652\n",
      "rcd_cte_concentrators, 492\n",
      "rcd_cte_credentials, 436\n",
      "rcd_cte_endorsement, 537\n",
      "rcd_cte_enrollment, 1184\n",
      "rcd_dlmi, 2723\n",
      "rcd_effectiveness, 2777\n",
      "rcd_experience, 2758\n",
      "rcd_funds, 292\n",
      "rcd_ib, 51\n",
      "rcd_improvement, 19\n",
      "rcd_inc2, 2792\n",
      "rcd_licenses, 3121\n",
      "rcd_location, 2759\n",
      "rcd_nbpts, 3124\n",
      "rcd_pk_enroll, 988\n",
      "rcd_readiness, 1323\n",
      "rcd_sar, 2630\n",
      "rcd_sat, 613\n",
      "rcd_welcome, 1311\n"
     ]
    }
   ],
   "source": [
    "print('Saving Flattened Versions and Record Counts for the Following Raw Data Files: \\n')\n",
    "for fileName in rcdFileNames:\n",
    "    eval(fileName).to_csv(dataDir + 'Flattened Datasets/' + fileName + '.csv', sep=',', index=False)\n",
    "    print(fileName + ', ' + str(len(eval(fileName).index)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Save Copy of the Original Statistical Profiles Data\n",
    "\n",
    "## -----------------  Manual Download Required!!! -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistical Profiles - Student Body Racial Compositions at the School Level\n",
    "#import io\n",
    "#import requests\n",
    "\n",
    "#url='http://apps.schools.nc.gov/ords/f?p=145:221::CSV::::'\n",
    "statProfPath = dataDir + 'SRC_Datasets/' + 'ec_pupils.csv'\n",
    "\n",
    "#Passing this URL directly into pd.read_csv() threw HTTP errors - This is my workaround\n",
    "#s = requests.get(url).content\n",
    "#ec_pupils = pd.read_csv(io.StringIO(s.decode('utf-8')), low_memory=False\n",
    "#                        , dtype={'LEA': object,'School': object})\n",
    "\n",
    "ec_pupils = pd.read_csv(statProfPath, low_memory=False\n",
    "                        , dtype={'LEA': object,'School': object})\n",
    "\n",
    "#Rename year for consistency\n",
    "ec_pupils.rename({'Year':'year', '____LEA Name____':'LEA Name', '___School Name___':'school name',\n",
    "                 'Two or  More Male':'two or more male', 'Two or  More Female':'two or more female'}, axis=1, inplace=True)\n",
    "\n",
    "#Create agency_code from LEA and School code as an index\n",
    "ec_pupils['agency_code'] = ec_pupils['LEA'] + ec_pupils['School']\n",
    "\n",
    "#Filter to 2018 school year (There is already 2019 school year data in this file)\n",
    "#ec_pupils = ec_pupils[ec_pupils.year == schoolYear]\n",
    "\n",
    "#Some schools are missing race data.  Get the most recent year of data available for each agency code\n",
    "ec_pupils = ec_pupils.sort_values(by=['agency_code', 'year'])\n",
    "ec_pupils = ec_pupils.drop_duplicates(subset=[\"agency_code\"], keep=\"last\")\n",
    "\n",
    "ec_pupils.columns = [i.lower() for i in ec_pupils.columns]\n",
    "\n",
    "#Save the original data to the source datasets folder \n",
    "ec_pupils.to_csv(statProfPath, sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Flattened Statistical Profiles with Racial Composition Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Flattened Versions and Record Counts for the Following Raw Data Files: \n",
      "\n",
      "ec_pupils_pct, 2494\n"
     ]
    }
   ],
   "source": [
    "#***********************************************************************\n",
    "# Statistical Profiles - Student Body Racial Compositions at the School Level Reshape\n",
    "#\n",
    "# Statistical Profiles data are already one record per public school but must be converted to percentages\n",
    "# Creates a new dataset - ec_pupils_pct.csv\n",
    "#\n",
    "#***********************************************************************\n",
    "\n",
    "#Statistical Profiles - Student Body Racial Compositions at the School Level\n",
    "ec_pupils = pd.read_csv(statProfPath, low_memory=False, dtype={'agency_code': object})\n",
    "\n",
    "#Create Racial Composition summary variables\n",
    "ec_pupils['indian'] = ec_pupils['indian male'] + ec_pupils['indian female']\n",
    "ec_pupils['asian'] = ec_pupils['asian male'] + ec_pupils['asian female']\n",
    "ec_pupils['hispanic'] = ec_pupils['hispanic male'] + ec_pupils['hispanic female']\n",
    "ec_pupils['black'] = ec_pupils['black male'] + ec_pupils['black female']\n",
    "ec_pupils['white'] = ec_pupils['white male'] + ec_pupils['white female']\n",
    "ec_pupils['pacific island'] = ec_pupils['pacific island male'] + ec_pupils['pacific island female']\n",
    "ec_pupils['two or more'] = ec_pupils['two or more male'] + ec_pupils['two or more female']\n",
    "\n",
    "#The original total field is corrupted with non-printable characters and will not convert to int or float \n",
    "ec_pupils.drop(['total'], axis=1, inplace=True)\n",
    "#Create a new totals field by summing race composition fields\n",
    "ec_pupils['total'] = ec_pupils['indian'] + ec_pupils['asian'] + \\\n",
    "                     ec_pupils['hispanic'] + ec_pupils['black'] + \\\n",
    "                     ec_pupils['white'] + ec_pupils['pacific island'] + ec_pupils['two or more']\n",
    "#Convert totals to float64 for division later\n",
    "ec_pupils['total'] = ec_pupils['total'].astype(np.float64)\n",
    "\n",
    "#Create minority summary variables \n",
    "ec_pupils['minority male'] = ec_pupils['indian male'] + ec_pupils['asian male'] \\\n",
    "                           + ec_pupils['hispanic male'] + ec_pupils['black male'] \\\n",
    "                           + ec_pupils['pacific island male'] + ec_pupils['two or more male'] \n",
    "ec_pupils['minority female'] = ec_pupils['indian female'] + ec_pupils['asian female'] \\\n",
    "                           + ec_pupils['hispanic female'] + ec_pupils['black female'] \\\n",
    "                           + ec_pupils['pacific island female'] + ec_pupils['two or more female']\n",
    "ec_pupils['minority'] = ec_pupils['minority male'] + ec_pupils['minority female']\n",
    "\n",
    "#Create Student Body Racial Composition PERCENTAGES at the School Level\n",
    "ec_pupils_pct = pd.DataFrame({'agency_code'   : ec_pupils['agency_code']\n",
    "                            , 'lea' : ec_pupils['lea']\n",
    "                            , 'lea_name' : ec_pupils['lea name']\n",
    "                            , 'school' : ec_pupils['school']\n",
    "                            , 'school_name' : ec_pupils['school name']\n",
    "                            , 'indian_pct'   : ec_pupils['indian'] / ec_pupils['total']  \n",
    "                            , 'asian_pct'    : ec_pupils['asian'] / ec_pupils['total']\n",
    "                            , 'hispanic_pct' : ec_pupils['hispanic'] / ec_pupils['total']\n",
    "                            , 'black_pct'    : ec_pupils['black'] / ec_pupils['total']\n",
    "                            , 'white_pct'    : ec_pupils['white'] / ec_pupils['total']\n",
    "                            , 'pacific_Island_pct': ec_pupils['pacific island'] / ec_pupils['total']\n",
    "                            , 'two_or_more_pct': ec_pupils['two or more'] / ec_pupils['total']\n",
    "                            , 'minority_pct' : ec_pupils['minority'] / ec_pupils['total']\n",
    "                            \n",
    "                              \n",
    "                            , 'indian_male_pct'   : ec_pupils['indian male'] / ec_pupils['total']  \n",
    "                            , 'asian_male_pct'    : ec_pupils['asian male'] / ec_pupils['total']\n",
    "                            , 'hispanic_male_pct' : ec_pupils['hispanic male'] / ec_pupils['total']\n",
    "                            , 'black_male_pct'    : ec_pupils['black male'] / ec_pupils['total']\n",
    "                            , 'white_male_pct'    : ec_pupils['white male'] / ec_pupils['total']\n",
    "                            , 'pacific_Island_male_pct': ec_pupils['pacific island male'] / ec_pupils['total']\n",
    "                            , 'two_or_more_male_pct': ec_pupils['two or more male'] / ec_pupils['total']  \n",
    "                            , 'minority_male_pct' : ec_pupils['minority male'] / ec_pupils['total']\n",
    "                                                          \n",
    "                            , 'indian_female_pct'   : ec_pupils['indian female'] / ec_pupils['total']  \n",
    "                            , 'asian_female_pct'    : ec_pupils['asian female'] / ec_pupils['total']\n",
    "                            , 'hispanic_female_pct' : ec_pupils['hispanic female'] / ec_pupils['total']\n",
    "                            , 'black_female_pct'    : ec_pupils['black female'] / ec_pupils['total']\n",
    "                            , 'white_female_pct'    : ec_pupils['white female'] / ec_pupils['total']\n",
    "                            , 'minority_female_pct' : ec_pupils['minority female'] / ec_pupils['total'] \n",
    "                            , 'pacific_Island_female_pct': ec_pupils['pacific island female'] / ec_pupils['total']\n",
    "                            , 'two_or_more_female_pct': ec_pupils['two or more female'] / ec_pupils['total']\n",
    "                             })\n",
    "\n",
    "ec_pupils_pct.columns = [i.lower() for i in ec_pupils_pct.columns]\n",
    "\n",
    "#Save the flattened racial composition percentage data to disk \n",
    "ec_pupils_pct.to_csv(dataDir + 'Flattened Datasets/' + 'ec_pupils_pct.csv', sep=',', index=False)\n",
    "\n",
    "#Print file details\n",
    "print('Saving Flattened Versions and Record Counts for the Following Raw Data Files: \\n')\n",
    "print('ec_pupils_pct' + ', ' + str(len(ec_pupils_pct.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process School Attendance Data\n",
    "\n",
    "## -----------------  Manual Download Required!!! -----------------\n",
    "\n",
    "### Notes on Attendance Data \n",
    "* **Location** - https://www.dpi.nc.gov/districts-schools/district-operations/financial-and-business-services/demographics-and-finances/student-accounting-data#average-daily-attendance-&-average-daily-membership-ratios-(ada:adm)\n",
    "* **Download: Average Daily Attendance & Average Daily Membership Ratios (ADA:ADM), Three-year historical attendance and membership data** - https://files.nc.gov/dpi/documents/fbs/accounting/data/adm/ratio.xlsx\n",
    "* **File Name** -Ratio.csv\n",
    "* This file needs manual processing \n",
    " 1. Delete notes page from spreadsheet\n",
    " 2. Remove empty columns in report and save as .csv file\n",
    " 3. Edit .csv file - delete 2 rows of column headings, add in column headings below.\n",
    "* **Column Names to Cut and Paste: ** - agency_code,lea_no,lea_name,school_no,school_name,grade_span,ada_ct_2017,adm_ct_2017,ada_adm_ratio_2018,ada_ct_2018,adm_ct_2018,ada_adm_ratio_2018,ada_ct_2019,adm_ct_2019,ada_adm_ratio_2019,ada_adm_ratio_2017_thru_2019,ada_adm_rank_2017_thru_2019\n",
    "* **MAKE SURE THE YEAR NUMBERS IN THE COLUMN NAMES ARE ACCURATE**\n",
    "\n",
    "### Metadata Details\n",
    "* **ada** = average daily attendance\n",
    "* **ama** = average daily membership"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicate agency codes\n",
    "**The duplicate agency code below was removed manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: agency_code, dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_readiness = pd.read_csv(dataDir + 'SRC_Datasets/' + 'ratio.csv', low_memory=False, dtype={'agency_code': object})\n",
    "vc = rcd_readiness['agency_code'].value_counts()\n",
    "vc[vc >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency_code</th>\n",
       "      <th>lea_no</th>\n",
       "      <th>lea_name</th>\n",
       "      <th>school_no</th>\n",
       "      <th>school_name</th>\n",
       "      <th>grade_span</th>\n",
       "      <th>ada_ct_2017</th>\n",
       "      <th>adm_ct_2017</th>\n",
       "      <th>ada_adm_ratio_2018</th>\n",
       "      <th>ada_ct_2018</th>\n",
       "      <th>adm_ct_2018</th>\n",
       "      <th>ada_adm_ratio_2018.1</th>\n",
       "      <th>ada_ct_2019</th>\n",
       "      <th>adm_ct_2019</th>\n",
       "      <th>ada_adm_ratio_2019</th>\n",
       "      <th>ada_adm_ratio_2017_thru_2019</th>\n",
       "      <th>ada_adm_rank_2017_thru_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>840361</td>\n",
       "      <td>840.0</td>\n",
       "      <td>Stanly County Schools</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Stanly Early College High</td>\n",
       "      <td>09-13</td>\n",
       "      <td>202</td>\n",
       "      <td>207</td>\n",
       "      <td>97.58</td>\n",
       "      <td>201</td>\n",
       "      <td>206</td>\n",
       "      <td>97.57</td>\n",
       "      <td>193</td>\n",
       "      <td>197</td>\n",
       "      <td>97.97</td>\n",
       "      <td>97.71</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     agency_code  lea_no               lea_name  school_no  \\\n",
       "2140      840361   840.0  Stanly County Schools      361.0   \n",
       "\n",
       "                    school_name grade_span ada_ct_2017 adm_ct_2017  \\\n",
       "2140  Stanly Early College High      09-13         202         207   \n",
       "\n",
       "      ada_adm_ratio_2018 ada_ct_2018 adm_ct_2018  ada_adm_ratio_2018.1  \\\n",
       "2140               97.58         201         206                 97.57   \n",
       "\n",
       "     ada_ct_2019 adm_ct_2019  ada_adm_ratio_2019  \\\n",
       "2140         193         197               97.97   \n",
       "\n",
       "      ada_adm_ratio_2017_thru_2019  ada_adm_rank_2017_thru_2019  \n",
       "2140                         97.71                         92.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcd_readiness[rcd_readiness.agency_code == '840361']\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File - ratio.csv\n",
    "#Found 0 duplicate agency_codes in this file at school level, no pivot \n",
    "rcd_readiness = pd.read_csv(dataDir + 'SRC_Datasets/' + 'ratio.csv', low_memory=False, dtype={'agency_code': object})\n",
    "rcd_readiness.columns = ['agency_code'] + [i.lower() + '_attendance' for i in rcd_readiness.columns if i != 'agency_code']\n",
    "rcd_readiness.to_csv(dataDir + 'Flattened Datasets/' + 'ratio.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
